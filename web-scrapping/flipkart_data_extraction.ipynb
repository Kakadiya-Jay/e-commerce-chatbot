{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb573a48-45e0-4f12-ae4c-b016df1d7f22",
   "metadata": {},
   "source": [
    "## This code contains a bug in it, so don't run it until the problem is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33c55ec-830a-4278-a605-2d34eed1ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.39.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting urllib3<3.0,>=2.5.0 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting certifi>=2025.10.5 (from selenium)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting typing_extensions<5.0,>=4.15.0 (from selenium)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (23.2.0)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.10)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.16.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Downloading selenium-4.39.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.7 MB 1.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.7 MB 1.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 2.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.6/9.7 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.8/9.7 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.8/9.7 MB 2.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.4/9.7 MB 1.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/9.7 MB 1.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.4/9.7 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.9/9.7 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.5/9.7 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.5/9.7 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.0/9.7 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.5/9.7 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.0/9.7 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.6/9.7 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.3/9.7 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.6/9.7 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.9/9.7 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.7/9.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 1.7 MB/s  0:00:05\n",
      "Downloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, urllib3, typing_extensions, outcome, certifi, trio, bs4, trio-websocket, selenium\n",
      "\n",
      "   ---- -----------------------------------  1/10 [wsproto]\n",
      "   ---- -----------------------------------  1/10 [wsproto]\n",
      "  Attempting uninstall: urllib3\n",
      "   ---- -----------------------------------  1/10 [wsproto]\n",
      "    Found existing installation: urllib3 1.26.20\n",
      "   ---- -----------------------------------  1/10 [wsproto]\n",
      "    Uninstalling urllib3-1.26.20:\n",
      "   ---- -----------------------------------  1/10 [wsproto]\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "      Successfully uninstalled urllib3-1.26.20\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "  Attempting uninstall: typing_extensions\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "   -------- -------------------------------  2/10 [urllib3]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "  Attempting uninstall: certifi\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "   ------------ ---------------------------  3/10 [typing_extensions]\n",
      "   -------------------- -------------------  5/10 [certifi]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   ------------------------ ---------------  6/10 [trio]\n",
      "   -------------------------------- -------  8/10 [trio-websocket]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ------------------------------------ ---  9/10 [selenium]\n",
      "   ---------------------------------------- 10/10 [selenium]\n",
      "\n",
      "Successfully installed bs4-0.0.2 certifi-2025.11.12 outcome-1.3.0.post0 selenium-4.39.0 sortedcontainers-2.4.0 trio-0.32.0 trio-websocket-0.12.2 typing_extensions-4.15.0 urllib3-2.6.2 wsproto-1.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.6.2 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.1 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32b708",
   "metadata": {},
   "source": [
    "**Import Key Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e87375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.keys import Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58094b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e69b41",
   "metadata": {},
   "source": [
    "### Step1: Get all product Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499f587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Start Time: 19:17:20.751590 ---------------------------> \n",
      "Waiting for search input...\n",
      "Typing in search input...\n",
      "Submitting search form...\n",
      "Waiting for search results...\n",
      "Collecting pagination links...\n",
      "Pagination Links Count: 25\n",
      "All Pagination Links:  ['https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=1', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=2', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=3', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=4', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=5', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=6', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=7', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=8', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=9', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=10', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=11', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=12', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=13', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=14', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=15', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=16', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=17', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=18', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=19', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=20', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=21', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=22', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=23', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=24', 'https://www.flipkart.com/search?q=sports+shoes+for+women&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=25']\n",
      "Collecting Product Detail Page Links\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\nSymbols not available. Dumping unresolved backtrace:\n\t0x7ff6b4a58245\n\t0x7ff6b4a582a0\n\t0x7ff6b483165d\n\t0x7ff6b4889a33\n\t0x7ff6b4889d3c\n\t0x7ff6b48ddf67\n\t0x7ff6b48dac97\n\t0x7ff6b487ac29\n\t0x7ff6b487ba93\n\t0x7ff6b4d6ffe0\n\t0x7ff6b4d6a920\n\t0x7ff6b4d89086\n\t0x7ff6b4a75744\n\t0x7ff6b4a7e6ec\n\t0x7ff6b4a61964\n\t0x7ff6b4a61b15\n\t0x7ff6b4a47842\n\t0x7ffb69c1e8d7\n\t0x7ffb6afec53c\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m WebDriverWait(driver, \u001b[38;5;241m120\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\u001b[38;5;28;01mlambda\u001b[39;00m d: d\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn document.readyState\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#wait until elements located\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrPDeLR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     58\u001b[0m all_products \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrPDeLR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m all_links \u001b[38;5;241m=\u001b[39m [element\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m all_products]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:122\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nSymbols not available. Dumping unresolved backtrace:\n\t0x7ff6b4a58245\n\t0x7ff6b4a582a0\n\t0x7ff6b483165d\n\t0x7ff6b4889a33\n\t0x7ff6b4889d3c\n\t0x7ff6b48ddf67\n\t0x7ff6b48dac97\n\t0x7ff6b487ac29\n\t0x7ff6b487ba93\n\t0x7ff6b4d6ffe0\n\t0x7ff6b4d6a920\n\t0x7ff6b4d89086\n\t0x7ff6b4a75744\n\t0x7ff6b4a7e6ec\n\t0x7ff6b4a61964\n\t0x7ff6b4a61b15\n\t0x7ff6b4a47842\n\t0x7ffb69c1e8d7\n\t0x7ffb6afec53c\n"
     ]
    }
   ],
   "source": [
    "#Inputs to search\n",
    "search_box_text = 'sports shoes for women'\n",
    "website_link = 'https://www.flipkart.com/'\n",
    "\n",
    "#initiating the browser\n",
    "#session start time\n",
    "session_start_time = datetime.now().time()\n",
    "print(f\"Session Start Time: {session_start_time} ---------------------------> \")\n",
    "\n",
    "\n",
    "#starting the browser\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(website_link)\n",
    "driver.maximize_window()\n",
    "\n",
    "print('Waiting for search input...')\n",
    "search_input = WebDriverWait(driver, 120).until(EC.presence_of_element_located((By.CSS_SELECTOR, '[autocomplete=\"off\"]'))) \n",
    "        \n",
    "print('Typing in search input...') \n",
    "search_input.send_keys(search_box_text) \n",
    "        \n",
    "print('Submitting search form...') \n",
    "search_input.send_keys(Keys.RETURN) \n",
    "        \n",
    "print('Waiting for search results...') \n",
    "WebDriverWait(driver, 120).until( EC.presence_of_element_located((By.CSS_SELECTOR, '[target=\"_blank\"]')) )\n",
    "\n",
    "print('Collecting pagination links...') \n",
    "\n",
    "\n",
    "#we want first 25 pages [pagination link]  [1000 Products]\n",
    "#logic: Let's get the first page pagination link and append the number in the end for 25 pages and store in a list\n",
    "all_pagination_links =[]\n",
    "\n",
    "first_page = driver.find_elements(By.CSS_SELECTOR, 'nav a')[0]\n",
    "first_page_link = first_page.get_attribute('href')\n",
    "all_pagination_links.append(first_page_link)\n",
    "\n",
    "for i in range(2, 26):\n",
    "    new_pagination_link = first_page_link[: -1] + str(i)\n",
    "    all_pagination_links.append(new_pagination_link)\n",
    "\n",
    "print('Pagination Links Count:', len(all_pagination_links)) \n",
    "print(\"All Pagination Links: \", all_pagination_links)\n",
    "\n",
    "\n",
    "print(\"Collecting Product Detail Page Links\")\n",
    "all_product_links = []\n",
    "\n",
    "for link in all_pagination_links:\n",
    "    driver.get(link)\n",
    "    # Wait for the page to load by checking document.readyState\n",
    "    WebDriverWait(driver, 120).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "\n",
    "    #wait until elements located\n",
    "    WebDriverWait(driver, 120).until(EC.presence_of_element_located((By.CLASS_NAME, 'rPDeLR'))) \n",
    "                \n",
    "    all_products = driver.find_elements(By.CLASS_NAME, 'rPDeLR')\n",
    "    all_links = [element.get_attribute('href') for element in all_products]\n",
    "\n",
    "    print(f\"{link} Done ------>\")\n",
    "\n",
    "    all_product_links.extend(all_links)\n",
    "    \n",
    "print('All Product Detail Page Links Captured: ', len(all_product_links)) \n",
    "\n",
    "\n",
    "# Creating a DataFrame from the list\n",
    "df_product_links = pd.DataFrame(all_product_links, columns=['product_links'])\n",
    "#remove any duplicates\n",
    "df_product_links = df_product_links.drop_duplicates(subset=['product_links'])\n",
    "\n",
    "print(\"Total Product Detail Page Links\", len(df_product_links))\n",
    "df_product_links.to_csv('flipkart_product_links.csv', index = False)\n",
    "\n",
    "driver.close()\n",
    "session_end_time = datetime.now().time()\n",
    "print(f\"Session End Time: {session_end_time} ---------------------------> \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66130763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b7f0b1",
   "metadata": {},
   "source": [
    "### Step2: Get Individual product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973de7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Start Time: 19:20:52.707328 ---------------------------> \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flipkart_product_links.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession Start Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---------------------------> \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#reading the csv file which contain all product links\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_product_links \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflipkart_product_links.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Remove the below line to scrap all the products. For demonstration purpose we are scraping only 10 products\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df_product_links \u001b[38;5;241m=\u001b[39m df_product_links\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m25\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flipkart_product_links.csv'"
     ]
    }
   ],
   "source": [
    "#session start time\n",
    "session_start_time = datetime.now().time()\n",
    "print(f\"Session Start Time: {session_start_time} ---------------------------> \")\n",
    "\n",
    "\n",
    "#reading the csv file which contain all product links\n",
    "df_product_links = pd.read_csv(\"flipkart_product_links.csv\")\n",
    "\n",
    "# Remove the below line to scrap all the products. For demonstration purpose we are scraping only 10 products\n",
    "df_product_links = df_product_links.head(25)\n",
    "\n",
    "all_product_links = df_product_links['product_links'].tolist()\n",
    "print(\"Collecting Individual Product Detail Information\")\n",
    "\n",
    "#starting the browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "complete_product_details = []\n",
    "unavailable_products = []\n",
    "successful_parsed_urls_count = 0\n",
    "complete_failed_urls_count = 0\n",
    "for product_page_link in all_product_links:\n",
    "\n",
    "    try: \n",
    "        driver.get(product_page_link)\n",
    "    \n",
    "        # Wait for the page to load by checking document.readyState\n",
    "        WebDriverWait(driver, 120).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "    \n",
    "        WebDriverWait(driver, 120).until( EC.presence_of_element_located((By.CSS_SELECTOR, '[target=\"_blank\"]')))\n",
    "    \n",
    "        #checking if product is available or not\n",
    "        try:\n",
    "            product_status =  driver.find_element(By.CLASS_NAME, 'Z8JjpR').text\n",
    "            if product_status == 'Currently Unavailable' or product_status == 'Sold Out':\n",
    "                unavailable_products.append(product_page_link)\n",
    "                successful_parsed_urls_count += 1\n",
    "                print(f\"URL {successful_parsed_urls_count} completed --->\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        #brand\n",
    "        brand =  driver.find_element(By.CLASS_NAME, 'mEh187').text\n",
    "    \n",
    "        #title       \n",
    "        title = driver.find_element(By.CLASS_NAME, 'VU-ZEz').text\n",
    "        title = re.sub(r'\\s*\\([^)]*\\)', '', title)  #removing data withing parenthesis (color information)\n",
    "    \n",
    "        #price      \n",
    "        price = driver.find_element(By.CLASS_NAME, 'Nx9bqj').text\n",
    "        price = re.findall(r'\\d+', price)\n",
    "        price = ''.join(price)\n",
    "    \n",
    "        # Discount  \n",
    "        try:\n",
    "            discount = driver.find_element(By.CLASS_NAME, 'UkUFwK').text\n",
    "            discount = re.findall(r'\\d+', discount)\n",
    "            discount = ''.join(discount)\n",
    "            discount = int(discount) / 100\n",
    "        except:\n",
    "            discount = ''\n",
    "    \n",
    "        #for a new product, there will be no avg_rating and total_ratings    \n",
    "        try:\n",
    "            product_review_status = driver.find_element(By.CLASS_NAME, 'E3XX7J').text\n",
    "            if product_review_status == 'Be the first to Review this product':\n",
    "                avg_rating = ''\n",
    "                total_ratings = ''\n",
    "        except:\n",
    "            avg_rating = driver.find_element(By.CLASS_NAME, 'XQDdHH').text\n",
    "            total_ratings = driver.find_element(By.CLASS_NAME, 'Wphh3N').text.split(' ')[0]\n",
    "            #remove the special character\n",
    "            if ',' in total_ratings:\n",
    "                total_ratings = int(total_ratings.replace(',', ''))\n",
    "            else:\n",
    "                total_ratings = int(total_ratings)\n",
    "    \n",
    "        successful_parsed_urls_count += 1\n",
    "        print(f\"URL {successful_parsed_urls_count} completed *******\")\n",
    "        complete_product_details.append([product_page_link, title, brand, price, discount, avg_rating, total_ratings])  \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to establish a connection for URL {product_page_link}:  {e}\")\n",
    "        unavailable_products.append(product_page_link)\n",
    "        complete_failed_urls_count += 1\n",
    "        print(f\"Failed URL Count {complete_failed_urls_count}\")\n",
    "\n",
    "\n",
    "#create pandas dataframe \n",
    "df = pd.DataFrame(complete_product_details, columns = ['product_link', 'title', 'brand', 'price', 'discount', 'avg_rating', 'total_ratings'])\n",
    "#duplicates processing\n",
    "df_duplicate_products = df[df.duplicated(subset=['brand', 'price', 'discount', 'avg_rating', 'total_ratings'])]\n",
    "df = df.drop_duplicates(subset=['brand', 'price', 'discount', 'avg_rating', 'total_ratings'])\n",
    "#unavailable products\n",
    "df_unavailable_products = pd.DataFrame(unavailable_products, columns=['link'])\n",
    "\n",
    "\n",
    "#prining the stats\n",
    "print(\"Total product pages scrapped: \", len(all_product_links))\n",
    "print(\"Final Total Products: \", len(df))\n",
    "print(\"Total Unavailable Products : \", len(df_unavailable_products))\n",
    "print(\"Total Duplicate Products: \", len(df_duplicate_products))\n",
    "\n",
    "\n",
    "#saving all the files\n",
    "df.to_csv('flipkart_product_data.csv', index = False)\n",
    "df_unavailable_products.to_csv('unavailable_products.csv', index = False)\n",
    "df_duplicate_products.to_csv('duplicate_products.csv', index = False)\n",
    "\n",
    "\n",
    "driver.close()\n",
    "session_end_time = datetime.now().time()\n",
    "print(f\"Session End Time: {session_end_time} ---------------------------> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82730141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
